# Pose Estimation for Human-Computer Interaction

This project implements a real-time pose estimation system using OpenPose (or MediaPipe Pose) to recognize human body keypoints for interactive applications. The goal is to enable gesture-based control for human-computer interaction (HCI).

##  Overview

- Extracts human body landmarks from video or webcam input
- Maps pose keypoints using deep learning models (e.g., MediaPipe or OpenPose)
- Supports interactive gesture recognition for HCI systems

##  Libraries and tools Used

- Python
- OpenCV
- MediaPipe / OpenPose
- NumPy, Matplotlib
- Google collab 

##  Features

- Real-time body pose detection (17+ keypoints)
- Visualization of skeleton overlays
- Potential integration with gesture-based commands or virtual controls

##  File Structure

- `Pose Estimation for Human-Computer Interaction.ipynb`: Main implementation notebook

##  Future Work

- Integration with virtual reality or smart environments
- Gesture classification (e.g., wave, sit, stand)
- UI feedback loop for full HCI demonstration
